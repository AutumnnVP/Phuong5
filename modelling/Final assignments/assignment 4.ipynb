{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE) for each fold: [2.39528241 2.13763369 2.27740749 2.234107   2.32644358]\n",
      "Average Prediction Error (MAE): 2.2741748340964287\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Step 1: Load dataset and create dummy variables\n",
    "df = pd.read_csv('/workspaces/Phuong5/1669242turnover.csv')\n",
    "df_encoded = pd.get_dummies(df, columns=['Disciplined', 'Social_drinker', 'Social_smoker'], drop_first=True)\n",
    "\n",
    "# Define dependent and independent variables\n",
    "y = df_encoded['Months_active']\n",
    "X = df_encoded.drop(columns=['Months_active', 'BMI', 'Weight'])  # Drop BMI and Weight due to multicollinearity\n",
    "\n",
    "# Convert to numeric (ensure all data is in the correct format)\n",
    "X = X.astype(float)\n",
    "y = y.astype(float)\n",
    "\n",
    "# Step 2: Set up the linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Step 3: Perform 5-fold cross-validation with mean absolute error\n",
    "# Note: cross_val_score returns negative MAE because it maximizes scores, so we negate it\n",
    "mae_scores = cross_val_score(model, X, y, cv=5, scoring='neg_mean_absolute_error')\n",
    "mae_scores = -mae_scores  # Convert to positive MAE\n",
    "\n",
    "# Calculate the average prediction error (mean absolute error)\n",
    "average_mae = np.mean(mae_scores)\n",
    "\n",
    "# Print the results\n",
    "print(\"Mean Absolute Error (MAE) for each fold:\", mae_scores)\n",
    "print(\"Average Prediction Error (MAE):\", average_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average prediction error: 2.27 months\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Prepare the data\n",
    "# Load the dataset\n",
    "df = pd.read_csv('/workspaces/Phuong5/1669242turnover.csv')\n",
    "\n",
    "# Select the target (dependent variable)\n",
    "y = df['Months_active']\n",
    "\n",
    "# Select features (independent variables) and drop unnecessary columns\n",
    "X = df.drop(columns=['Months_active', 'BMI', 'Weight'])  # Drop BMI and Weight due to multicollinearity\n",
    "\n",
    "# Turn categorical variables into dummy variables\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Ensure all data is numeric\n",
    "X = X.astype(float)\n",
    "y = y.astype(float)\n",
    "\n",
    "# Predict with all features\n",
    "# Define the cross-validation (5 folds)\n",
    "cv = 5  # 5-fold cross-validation\n",
    "\n",
    "# Predict with linear regression\n",
    "lm = LinearRegression()\n",
    "lmscores = cross_val_score(lm, X, y, scoring='neg_mean_absolute_error', cv=cv)\n",
    "\n",
    "# Calculate the overall mean absolute error (MAE)\n",
    "lmMAE = np.mean(np.absolute(lmscores))\n",
    "\n",
    "# Print the result\n",
    "print(f\"The average prediction error: {lmMAE:.2f} months\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best alpha value found is: 100\n",
      "The average prediction error with ridge is: 2.24 months\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "\n",
    "# Step 1: Load dataset and prepare the data\n",
    "df = pd.read_csv('/workspaces/Phuong5/1669242turnover.csv')\n",
    "\n",
    "# Select the target (dependent variable)\n",
    "y = df['Months_active']\n",
    "\n",
    "# Select features (independent variables) and drop unnecessary columns\n",
    "X = df.drop(columns=['Months_active', 'BMI', 'Weight'])  # Drop BMI and Weight due to multicollinearity\n",
    "\n",
    "# Turn categorical variables into dummy variables\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Ensure all data is numeric\n",
    "X = X.astype(float)\n",
    "y = y.astype(float)\n",
    "\n",
    "# Step 2: Normalize the data\n",
    "scaler = StandardScaler()\n",
    "X_normalized = scaler.fit_transform(X)\n",
    "\n",
    "# Step 3: Find the best alpha using grid search with 5-fold cross-validation\n",
    "# Define the ridge regression model\n",
    "ridge = Ridge()\n",
    "\n",
    "# Define the range of alpha values to test\n",
    "param_grid = {'alpha': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
    "\n",
    "# Set up grid search with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(estimator=ridge, param_grid=param_grid, \n",
    "                           scoring='neg_mean_absolute_error', cv=5)\n",
    "\n",
    "# Fit the grid search to the normalized data\n",
    "grid_search.fit(X_normalized, y)\n",
    "\n",
    "# Get the best alpha value\n",
    "best_alpha = grid_search.best_params_['alpha']\n",
    "print(f\"The best alpha value found is: {best_alpha}\")\n",
    "\n",
    "# Step 4: Run ridge regression with the best alpha and calculate MAE (following the example)\n",
    "# Define the model and alpha\n",
    "RidgeModel = Ridge(alpha=best_alpha)\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "cv = 5\n",
    "\n",
    "# Run the cross-fold validation again (same as earlier)\n",
    "scoresridge = cross_val_score(RidgeModel, X_normalized, y, scoring='neg_mean_absolute_error', cv=cv)\n",
    "\n",
    "# Calculate the overall mean absolute error\n",
    "ridgeMAE = np.mean(np.absolute(scoresridge))\n",
    "\n",
    "# Print the result\n",
    "print(f\"The average prediction error with ridge is: {ridgeMAE:.2f} months\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average prediction error with the neural network is: 0.29 months\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "import tensorflow as tf\n",
    "\n",
    "# Step 1: Load dataset and prepare the data\n",
    "df = pd.read_csv('/workspaces/Phuong5/1669242turnover.csv')\n",
    "\n",
    "# Select the target (dependent variable)\n",
    "y = df['Months_active']\n",
    "\n",
    "# Select features (independent variables) and drop unnecessary columns\n",
    "X = df.drop(columns=['Months_active', 'BMI', 'Weight'])  # Drop BMI and Weight due to multicollinearity\n",
    "\n",
    "# Turn categorical variables into dummy variables\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Ensure all data is numeric\n",
    "X = X.astype(float)\n",
    "y = y.astype(float)\n",
    "\n",
    "# Step 2: Normalize the data\n",
    "scaler = StandardScaler()\n",
    "X_normalized = scaler.fit_transform(X)\n",
    "\n",
    "# Step 3: Define a function to create the neural network model\n",
    "def create_model(input_shape):\n",
    "    # Create the model\n",
    "    nnmodel = Sequential([\n",
    "        Input(shape=(input_shape,)),  # Input layer\n",
    "        Dense(512, activation='relu'),  # Hidden layer 1: 512 nodes, ReLU activation\n",
    "        Dense(512, activation='relu'),  # Hidden layer 2: 512 nodes, ReLU activation\n",
    "        Dense(512, activation='relu'),  # Hidden layer 3: 512 nodes, ReLU activation\n",
    "        Dense(512, activation='relu'),  # Hidden layer 4: 512 nodes, ReLU activation\n",
    "        Dense(512, activation='relu'),  # Hidden layer 5: 512 nodes, ReLU activation\n",
    "        Dense(1)  # Output layer\n",
    "    ])\n",
    "    \n",
    "    # Compile the model\n",
    "    nnmodel.compile(loss='mean_absolute_error',  # Loss calculated with MAE\n",
    "                    optimizer='adam',  # Adam optimizer\n",
    "                    metrics=['mae'])  # Use MAE to evaluate the model\n",
    "    \n",
    "    return nnmodel\n",
    "\n",
    "# Step 4: Perform 5-fold cross-validation manually\n",
    "# Define the cross-validation (5 folds, as specified in Assignment 4)\n",
    "kfold = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "\n",
    "# Initialize a list to store the MAE for each fold\n",
    "mae_scores = []\n",
    "\n",
    "# Convert X and y to numpy arrays for indexing\n",
    "X_normalized = np.array(X_normalized)\n",
    "y = np.array(y)\n",
    "\n",
    "# Perform cross-validation\n",
    "for train_index, test_index in kfold.split(X_normalized):\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test = X_normalized[train_index], X_normalized[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Create a new model for this fold\n",
    "    model = create_model(input_shape=X_train.shape[1])\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, \n",
    "              epochs=100,  # Number of epochs\n",
    "              batch_size=16,  # Batch size\n",
    "              verbose=0)  # Suppress training output\n",
    "    \n",
    "    # Evaluate the model on the test set\n",
    "    y_pred = model.predict(X_test, verbose=0)\n",
    "    mae = np.mean(np.abs(y_test - y_pred.flatten()))  # Calculate MAE\n",
    "    \n",
    "    # Store the MAE for this fold\n",
    "    mae_scores.append(mae)\n",
    "\n",
    "# Step 5: Calculate the average prediction error\n",
    "nn_mae = np.mean(mae_scores)\n",
    "\n",
    "# Print the result\n",
    "print(f\"The average prediction error with the neural network is: {nn_mae:.2f} months\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
